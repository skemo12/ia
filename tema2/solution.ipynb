{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from scipy.stats import pointbiserialr, chi2_contingency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATT_INT = [\"Administrative\", \"Informational\", \"ProductRelated\"]\n",
    "ATT_INT_CATEGORY = [\"OperatingSystems\", \"Browser\", \"Region\", \"TrafficType\"]\n",
    "ATT_FLOAT = [\"Administrative_Duration\", \"Informational_Duration\", \"ProductRelated_Duration\", \"BounceRates\", \"ExitRates\", \"PageValues\", \"SpecialDay\"]\n",
    "ATT_STRING = [\"Month\", \"VisitorType\"]\n",
    "ATT_BOOL = [\"Weekend\", \"Revenue\"]\n",
    "ATT_BOOL_NO_TARGET = [\"Weekend\"]\n",
    "\n",
    "TARGET = \"Revenue\"\n",
    "\n",
    "RANDOM_STATES = [0, 1, 5, 7, 13, 23, 29, 32, 37, 42]\n",
    "\n",
    "SCALERS = [None, MinMaxScaler, StandardScaler, RobustScaler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count the number of occurrences of each class\n",
    "class_counts = df[TARGET].value_counts()\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Revenue')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Overall Class Distribution')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, y_train, y_test = train_test_split(df.drop(TARGET, axis=1), df[TARGET], test_size=0.2, random_state=42)\n",
    "trues_train = y_train[y_train == True].count()\n",
    "false_train = y_train[y_train == False].count()\n",
    "trues_test = y_test[y_test == True].count()\n",
    "false_test = y_test[y_test == False].count()\n",
    "\n",
    "# Count the number of occurrences of each class\n",
    "class_counts = [false_train, trues_train]\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(x=[False, True], y=class_counts)\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Revenue')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution Train state 42')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Count the number of occurrences of each class\n",
    "class_counts_test = [false_test, trues_test]\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(x=[False, True], y=class_counts_test)\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Revenue')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution Test state 42')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues_train = 0\n",
    "false_train = 0\n",
    "trues_test = 0\n",
    "false_test = 0\n",
    "\n",
    "for state in RANDOM_STATES:\n",
    "    _, _, y_train, y_test = train_test_split(df.drop(TARGET, axis=1), df[TARGET], test_size=0.2, random_state=state)\n",
    "\n",
    "    trues_train += y_train[y_train == True].count()\n",
    "    false_train += y_train[y_train == False].count()\n",
    "    trues_test += y_test[y_test == True].count()\n",
    "    false_test += y_test[y_test == False].count()\n",
    "\n",
    "trues_train /= len(RANDOM_STATES)\n",
    "false_train /= len(RANDOM_STATES)\n",
    "trues_test /= len(RANDOM_STATES)\n",
    "false_test /= len(RANDOM_STATES)\n",
    "\n",
    "print(\"Train: \", trues_train, false_train)\n",
    "print(\"Test: \", trues_test, false_test)\n",
    "\n",
    "# Count the number of occurrences of each class\n",
    "class_counts = [false_train, trues_train]\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(x=[False, True], y=class_counts)\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Revenue')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution Train average')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Count the number of occurrences of each class\n",
    "class_counts_test = [false_test, trues_test]\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(x=[False, True], y=class_counts_test)\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Revenue')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution Test average')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza date 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a numerice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for x in ATT_INT + ATT_FLOAT:\n",
    "    # Calculate the percentiles for each attribute\n",
    "    x_min = df[x].min()\n",
    "    x_max = df[x].max()\n",
    "    intervals = np.linspace(x_min, x_max, 11)\n",
    "\n",
    "    # Create a bar chart\n",
    "    df[x + '_interval'] = pd.cut(df[x], intervals)\n",
    "    interval_counts = df[x + '_interval'].value_counts().sort_index()\n",
    "\n",
    "    # Plot the values for each interval with logarithmic count (base 2)\n",
    "    interval_counts.plot(kind='bar', logy=True)\n",
    "    plt.xlabel('Interval')\n",
    "    plt.ylabel('Count (log scale)')\n",
    "    plt.title(f'Values for {x} in Intervals')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b categorice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ATT_INT_CATEGORY + ATT_STRING + ATT_BOOL:\n",
    "    # Create a bar chart\n",
    "    interval_counts = df[x].value_counts().sort_index()\n",
    "\n",
    "    # Plot the values for each interval with logarithmic count (base 2)\n",
    "    interval_counts.plot(kind='bar',\n",
    "                         )\n",
    "    plt.xlabel('Interval')\n",
    "    plt.ylabel('Count (log scale)')\n",
    "    plt.title(f'Values for {x}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 numerice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Point-Biserial Correlation for each numerical attribute\n",
    "\n",
    "correlation_p_df = pd.DataFrame(columns=['Attribute', 'Correlation', 'P-Value'])\n",
    "correlation_p_df_category = pd.DataFrame(columns=['Attribute', 'Correlation', 'P-Value'])\n",
    "\n",
    "for attribute in ATT_INT + ATT_FLOAT:\n",
    "    correlation, p_value = pointbiserialr(df[attribute], df[TARGET])\n",
    "    correlation_p_df.loc[len(correlation_p_df)] = [attribute, correlation, p_value]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for attribute in ATT_BOOL + ATT_INT_CATEGORY + ATT_STRING:\n",
    "    if attribute == TARGET:\n",
    "        continue\n",
    "    # Create a contingency table\n",
    "    contingency = pd.crosstab(df[attribute], df[TARGET])\n",
    "\n",
    "    # Calculate the Chi-Square statistic and the associated p-value\n",
    "    correlation, p_value, dof, expected = chi2_contingency(contingency)\n",
    "\n",
    "    correlation_p_df_category.loc[len(correlation_p_df_category)] = [attribute, correlation, p_value]\n",
    "\n",
    "# Print the correlation and p-value dictionaries\n",
    "print(\"Point Biserial Correlation\")\n",
    "print(correlation_p_df)\n",
    "\n",
    "\n",
    "print(\"\\nChi-Square Correlation\")\n",
    "print(correlation_p_df_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "df_copy = df.copy()\n",
    "\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode labels for each column in the dataframe\n",
    "for column in df_copy.columns:\n",
    "    df_copy[column] = label_encoder.fit_transform(df_copy[column])\n",
    "\n",
    "matrix = df_copy.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "# Plotting correlation matrix with 2 decimal places\n",
    "sns.heatmap(matrix.round(2), cmap=\"Greens\", annot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the attributes with p-value lower than 0.05\n",
    "filtered_attributes = correlation_p_df[correlation_p_df['P-Value'] < 0.05]['Attribute']\n",
    "\n",
    "plt.close()\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Create a bar chart plot for each filtered attribute\n",
    "for attribute in filtered_attributes:\n",
    "    # Get the correlation value for the attribute\n",
    "    correlation = correlation_p_df.loc[correlation_p_df['Attribute'] == attribute, 'Correlation'].values[0]\n",
    "\n",
    "    # Create a bar plot\n",
    "    plt.bar(attribute, correlation)\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Attribute')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Point-Biserial Correlation')\n",
    "plt.title('Point-Biserial Correlation for Attributes with P-Value < 0.05')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the attributes with p-value lower than 0.05\n",
    "filtered_attributes = correlation_p_df_category[correlation_p_df_category['P-Value'] < 0.05]['Attribute']\n",
    "\n",
    "plt.close()\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Create a bar chart plot for each filtered attribute\n",
    "for attribute in filtered_attributes:\n",
    "    # Get the correlation value for the attribute\n",
    "    correlation = correlation_p_df_category.loc[correlation_p_df_category['Attribute'] == attribute, 'Correlation'].values[0]\n",
    "\n",
    "    # Create a bar plot\n",
    "    plt.bar(attribute, correlation)\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Attribute')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Logarithmic Chi-squared Correlation')\n",
    "plt.title('Logarithmic Chi-squared Correlation for Attributes with P-Value < 0.05')\n",
    "plt.yscale('log')\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresie Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(df, scaler, state):\n",
    "    print(\"Creating model...\")\n",
    "    # Create the logistic regression model\n",
    "    model = LogisticRegression(max_iter=df.shape[0])\n",
    "    # Create an instance of LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Convert categorical variables to numerical labels\n",
    "    for column in df_copy.columns:\n",
    "        df_copy[column] = label_encoder.fit_transform(df_copy[column])\n",
    "\n",
    "\n",
    "    # Split the dataset into features (X) and target variable (y)\n",
    "    X = df_copy.drop(TARGET, axis=1)\n",
    "    y = df_copy[TARGET]\n",
    "\n",
    "    # # Apply the scaler if provided\n",
    "    if scaler is not None:\n",
    "        scaler = scaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=state)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_simple, X_test, y_test = create_model(df, None, 42)\n",
    "# Predict the labels for the test set\n",
    "y_pred = model_simple.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "average_accuracy = [[], [], [], []]\n",
    "average_precision = [[], [], [], []]\n",
    "average_recall = [[], [], [], []]\n",
    "average_f1 = [[], [], [], []]\n",
    "for state in RANDOM_STATES:\n",
    "    print(f\"Random state: {state}\")\n",
    "    for i, scaler in enumerate(SCALERS):\n",
    "        print(f\"Scaler: {scaler.__name__ if scaler is not None else None}\")\n",
    "        model, X_test, y_test = create_model(df, scaler, state)\n",
    "        # Predict the labels for the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate the accuracy score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(f'Test accuracy: {accuracy}')\n",
    "        print(f'Precision: {precision}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'F1 score: {f1}\\n')\n",
    "\n",
    "        average_accuracy[i].append(accuracy)\n",
    "        average_precision[i].append(precision)\n",
    "        average_recall[i].append(recall)\n",
    "        average_f1[i].append(f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, scaler in enumerate(SCALERS):\n",
    "    print(f\"Scaler: {scaler.__name__ if scaler is not None else None}\")\n",
    "\n",
    "    print(f'Variance of accuracy: {np.var(average_accuracy[i])}')\n",
    "    print(f'Variance of precision: {np.var(average_precision[i])}')\n",
    "    print(f'Variance of recall: {np.var(average_recall[i])}')\n",
    "    print(f'Variance of F1 score: {np.var(average_f1[i])}\\n')\n",
    "\n",
    "    print(f'Average accuracy: {np.mean(average_accuracy[i])}')\n",
    "    print(f'Average precision: {np.mean(average_precision[i])}')\n",
    "    print(f'Average recall: {np.mean(average_recall[i])}')\n",
    "    print(f'Average F1 score: {np.mean(average_f1[i])}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "class MyLogisticRegression:\n",
    "    def __init__(self, lr=.01, epochs_no=100):\n",
    "        self.lr = lr\n",
    "        self.epochs_no = epochs_no\n",
    "        self.W = None\n",
    "\n",
    "    def nll(self, Y, T):\n",
    "        return -np.sum(T * np.log(Y) + (1 - T) * np.log(1 - Y))\n",
    "\n",
    "    def train(self, X, T):\n",
    "        (N, D) = X.shape\n",
    "        X_hat = np.concatenate([X, np.ones((N, 1))], axis=1)\n",
    "        W = np.random.randn((D+1))\n",
    "\n",
    "        for _ in range(self.epochs_no):\n",
    "            W = W - X_hat.T @ (expit(X_hat @ W) - T) * self.lr / N\n",
    "        self.W =  W\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = expit(np.concatenate([X, np.ones((X.shape[0], 1))], axis=1) @ self.W)\n",
    "        for i in range(len(y)):\n",
    "            if y[i] >= 0.5:\n",
    "                y[i] = 1\n",
    "            else:\n",
    "                y[i] = 0\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_my_model(df, scaler, state):\n",
    "    print(\"Creating model...\")\n",
    "    # Create the logistic regression model\n",
    "    model = MyLogisticRegression(lr=.01, epochs_no=1000)\n",
    "    # Create an instance of LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Convert categorical variables to numerical labels\n",
    "    for column in df_copy.columns:\n",
    "        df_copy[column] = label_encoder.fit_transform(df_copy[column])\n",
    "\n",
    "\n",
    "    # Split the dataset into features (X) and target variable (y)\n",
    "    X = df_copy.drop(TARGET, axis=1)\n",
    "    y = df_copy[TARGET]\n",
    "\n",
    "    # # Apply the scaler if provided\n",
    "    if scaler is not None:\n",
    "        scaler = scaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=state)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    model.train(X_train, y_train)\n",
    "\n",
    "    return model, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracy = [[], [], [], []]\n",
    "average_precision = [[], [], [], []]\n",
    "average_recall = [[], [], [], []]\n",
    "average_f1 = [[], [], [], []]\n",
    "for state in [42]:\n",
    "    print(f\"Random state: {state}\")\n",
    "    for i, scaler in enumerate(SCALERS):\n",
    "        print(f\"Scaler: {scaler.__name__ if scaler is not None else None}\")\n",
    "        model, X_test, y_test = create_my_model(df, scaler, state)\n",
    "        # Predict the labels for the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Calculate the accuracy score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(f'Test accuracy: {accuracy}')\n",
    "        print(f'Precision: {precision}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'F1 score: {f1}\\n')\n",
    "\n",
    "        average_accuracy[i].append(accuracy)\n",
    "        average_precision[i].append(precision)\n",
    "        average_recall[i].append(recall)\n",
    "        average_f1[i].append(f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, scaler in enumerate(SCALERS):\n",
    "    print(f\"Scaler: {scaler.__name__ if scaler is not None else None}\")\n",
    "\n",
    "    print(f'Variance of accuracy: {np.var(average_accuracy[i])}')\n",
    "    print(f'Variance of precision: {np.var(average_precision[i])}')\n",
    "    print(f'Variance of recall: {np.var(average_recall[i])}')\n",
    "    print(f'Variance of F1 score: {np.var(average_f1[i])}\\n')\n",
    "\n",
    "    print(f'Average accuracy: {np.mean(average_accuracy[i])}')\n",
    "    print(f'Average precision: {np.mean(average_precision[i])}')\n",
    "    print(f'Average recall: {np.mean(average_recall[i])}')\n",
    "    print(f'Average F1 score: {np.mean(average_f1[i])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbori de decizize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def create_decision_tree_model(df, scaler, state, depth):\n",
    "    print(\"Creating model...\")\n",
    "    # Create the logistic regression model\n",
    "\n",
    "\n",
    "\n",
    "    # Create an instance of LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Convert categorical variables to numerical labels\n",
    "    for column in df_copy.columns:\n",
    "        df_copy[column] = label_encoder.fit_transform(df_copy[column])\n",
    "\n",
    "\n",
    "    # Split the dataset into features (X) and target variable (y)\n",
    "    X = df_copy.drop(TARGET, axis=1)\n",
    "    y = df_copy[TARGET]\n",
    "\n",
    "    # # Apply the scaler if provided\n",
    "    if scaler is not None:\n",
    "        scaler = scaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=state)\n",
    "\n",
    "    # Create an instance of DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier(random_state=state, max_depth=depth)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    return clf, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, X_test, y_test = create_decision_tree_model(df, None, 42, 6)\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 score: {f1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracy = [[], [], [], []]\n",
    "average_precision = [[], [], [], []]\n",
    "average_recall = [[], [], [], []]\n",
    "average_f1 = [[], [], [], []]\n",
    "for state in [42]:\n",
    "    print(f\"Random state: {state}\")\n",
    "    for i, scaler in enumerate(SCALERS):\n",
    "        print(f\"Scaler: {scaler.__name__ if scaler is not None else None}\")\n",
    "        model, X_test, y_test = create_decision_tree_model(df, scaler, state)\n",
    "        # Predict the labels for the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Calculate the accuracy score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(f'Test accuracy: {accuracy}')\n",
    "        print(f'Precision: {precision}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'F1 score: {f1}\\n')\n",
    "\n",
    "        average_accuracy[i].append(accuracy)\n",
    "        average_precision[i].append(precision)\n",
    "        average_recall[i].append(recall)\n",
    "        average_f1[i].append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "import csv\n",
    "import os\n",
    "\n",
    "class Node:\n",
    "    \"\"\" Representation for a node from the decision tree \"\"\"\n",
    "    def __init__(self, label):\n",
    "        \"\"\"\n",
    "            for non-leafs it is the name of the attribute\n",
    "            for leafs it is the class\n",
    "        \"\"\"\n",
    "        self.label = label\n",
    "\n",
    "        # Dictionary of (attribute value, nodes)\n",
    "        self.children = {}\n",
    "\n",
    "    def display(self, indent = \"\"):\n",
    "        print(indent + (self.label + \":\" if self.children else \"<\" + self.label + \">\"))\n",
    "        indent += \"   \"\n",
    "        if self.children:\n",
    "            for key, value in self.children.items():\n",
    "                print(indent + \":\" + key)\n",
    "                value.display(indent + \"   \")\n",
    "\n",
    "\n",
    "def getDataSet():\n",
    "    \"\"\" Reads a dataset\n",
    "\n",
    "    Args:\n",
    "        dataSetName (str): Name for the dataset\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing (classes, attributes, examples):\n",
    "        classes (set): the classes that are found in the dataset\n",
    "        attributes (list of strings): the attributes for the dataset\n",
    "        examples (list of dictionaries): one example contains an entry as\n",
    "            (attribute name, attribute value)\n",
    "    \"\"\"\n",
    "\n",
    "    dataset_file = \"dataset.csv\"\n",
    "    from os import path\n",
    "\n",
    "\n",
    "    f_in = open(dataset_file, 'r')\n",
    "    csv_reader = csv.reader(f_in, delimiter=\",\")\n",
    "\n",
    "    # Read the header row\n",
    "    row = next(csv_reader)\n",
    "\n",
    "    # The last element represents the class\n",
    "    attributeNames = row[:-1]\n",
    "\n",
    "    examples = []\n",
    "    classes = set()\n",
    "\n",
    "    for row in csv_reader:\n",
    "        *attributes, label = row\n",
    "        classes.add(label)\n",
    "        example = dict(zip(attributeNames, attributes))\n",
    "        example[TARGET] = label\n",
    "        examples.append(example)\n",
    "\n",
    "    f_in.close()\n",
    "    return classes, attributeNames, examples\n",
    "\n",
    "def mostFrequentClass(X):\n",
    "    # TODO 1a\n",
    "    rez = Counter(list(map(lambda x: x[TARGET], X)))\n",
    "    max_ap = 0\n",
    "    for i in rez:\n",
    "        if rez[i] > max_ap:\n",
    "            max_ap = rez[i]\n",
    "            cls_max = i\n",
    "    return cls_max\n",
    "\n",
    "\n",
    "def entropy(X):\n",
    "    entropy = 0\n",
    "    rez = Counter(list(map(lambda x: x[TARGET], X)))\n",
    "    total = 0\n",
    "    for i in rez:\n",
    "        total += rez[i]\n",
    "    for c in rez:\n",
    "        if(rez[c] > 0):\n",
    "            entropy += rez[c]/total * math.log2(rez[c]/total)\n",
    "    return -entropy\n",
    "\n",
    "def gain(X, a):\n",
    "    # TODO 2b\n",
    "    rez = Counter(list(map(lambda x: x[TARGET], X)))\n",
    "    total = 0\n",
    "    for i in rez:\n",
    "        total += rez[i]\n",
    "    sum = 0\n",
    "    rez = Counter(list(map(lambda x: x[a], X)))\n",
    "    for i in rez:\n",
    "        Xij = list(filter(lambda x: x[a] == i, X))\n",
    "        sum += len(Xij)/total * entropy(Xij)\n",
    "\n",
    "    return entropy(X) - sum\n",
    "\n",
    "def get_max_atr(X, list_atr):\n",
    "    scores = list(map(lambda x: gain(X, x), list_atr))\n",
    "    index_max = scores.index(max(scores))\n",
    "    return list_atr[index_max]\n",
    "\n",
    "\n",
    "def id3(X, A, d = 6):\n",
    "    # TODO 2c\n",
    "    # rez = Counter(list(map(lambda x: x[TARGET], X)))\n",
    "    # if len(rez) == 1:\n",
    "    #     keys = list(X[0].keys())\n",
    "    #     key = keys[0]\n",
    "    #     return Node(key)\n",
    "    if d == 0 or len(A) == 0:\n",
    "        return Node(mostFrequentClass(X))\n",
    "    elif d > 0:\n",
    "        atr = get_max_atr(X, A)\n",
    "        rez = Counter(list(map(lambda x: x[atr], X)))\n",
    "        A_new =  list(filter(lambda x: x != atr, A))\n",
    "        children = {}\n",
    "        for i in rez:\n",
    "            X_new = list(filter(lambda x: x[atr] == i, X))\n",
    "            children[i] = id3(X_new, A_new, d - 1)\n",
    "        node = Node(atr)\n",
    "        node.children = children\n",
    "        return node\n",
    "\n",
    "    return Node(\"\")\n",
    "\n",
    "def evaluate(tree, example):\n",
    "    '''\n",
    "    Functia intoarce clasa prezisa de arborele `tree` pentru exemplul `example`\n",
    "    '''\n",
    "    # TODO 2d\n",
    "    node = tree\n",
    "    while len(node.children) > 0:\n",
    "        node = node.children[example[node.label]]\n",
    "    return node.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TRUE', 'FALSE'}\n",
      "['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']\n"
     ]
    }
   ],
   "source": [
    "classes, attributes, examples = getDataSet()\n",
    "print(classes)\n",
    "print(attributes)\n",
    "tree = id3(examples, attributes, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241m.\u001b[39mdisplay()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m examples:\n\u001b[1;32m      5\u001b[0m     y_pred\u001b[38;5;241m.\u001b[39mappend(evaluate(tree, i))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "tree.display()\n",
    "\n",
    "for i in examples:\n",
    "    y_pred.append(evaluate(tree, i))\n",
    "y_values = list(map(lambda x: x[TARGET], examples))\n",
    "print(y_values)\n",
    "print(y_pred)\n",
    "accuracy = accuracy_score(y_values, y_pred)\n",
    "precision = precision_score(y_values, y_pred)\n",
    "recall = recall_score(y_values, y_pred)\n",
    "f1 = f1_score(y_values, y_pred)\n",
    "\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 score: {f1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MyDecisionTree:\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def gini_index(self, X):\n",
    "        gini = 1\n",
    "        total = len(X)\n",
    "        classes = Counter(X)\n",
    "        for c in classes:\n",
    "            p = classes[c] / total\n",
    "            gini -= p ** 2\n",
    "        return gini\n",
    "\n",
    "    def get_best_attribute(self, X, y):\n",
    "        best_attribute = None\n",
    "        best_gini_index = float('inf')\n",
    "        for attribute in X.columns:\n",
    "            gini_index = 0\n",
    "            attribute_values = X[attribute].unique()\n",
    "            for value in attribute_values:\n",
    "                subset = y[X[attribute] == value]\n",
    "                gini_index += len(subset) / len(y) * self.gini_index(subset)\n",
    "            if gini_index < best_gini_index:\n",
    "                best_gini_index = gini_index\n",
    "                best_attribute = attribute\n",
    "        return best_attribute\n",
    "\n",
    "    def id3(self, X, y, depth):\n",
    "        if depth == 0 or len(y.unique()) == 1:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "        if len(X.columns) == 0:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "        if depth > self.max_depth:\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "        best_attribute = self.get_best_attribute(X, y)\n",
    "        tree = {best_attribute: {}}\n",
    "        attribute_values = X[best_attribute].unique()\n",
    "        for value in attribute_values:\n",
    "            subset_X = X[X[best_attribute] == value].drop(columns=best_attribute)\n",
    "            subset_y = y[X[best_attribute] == value]\n",
    "            tree[best_attribute][value] = self.id3(subset_X, subset_y, depth + 1)\n",
    "        return tree\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.tree = self.id3(X_train, y_train, 0)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if isinstance(X_test, np.ndarray):\n",
    "            X_test = pd.DataFrame(X_test)\n",
    "        predictions = []\n",
    "        for _, instance in X_test.iterrows():\n",
    "            predictions.append(self.traverse_tree(instance, self.tree))\n",
    "        return predictions\n",
    "\n",
    "    def traverse_tree(self, instance, tree):\n",
    "        if not isinstance(tree, dict):\n",
    "            return tree\n",
    "        attribute = next(iter(tree))\n",
    "        value = instance[attribute]\n",
    "        if value in tree[attribute]:\n",
    "            subtree = tree[attribute][value]\n",
    "        else:\n",
    "            return None\n",
    "        return self.traverse_tree(instance, subtree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def gini_index(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        gini = 1 - np.sum(probabilities**2)\n",
    "        return gini\n",
    "\n",
    "    def get_best_split(self, X, y):\n",
    "        m, n = X.shape\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        num_classes = len(np.unique(y))\n",
    "        if num_classes == 1:\n",
    "            return None, None\n",
    "\n",
    "        current_gini = self.gini_index(y)\n",
    "        best_gini = float('inf')\n",
    "        best_index = None\n",
    "        best_value = None\n",
    "\n",
    "        for col in range(n):\n",
    "            values = np.unique(X[:, col])\n",
    "            for value in values:\n",
    "                left_mask = X[:, col] <= value\n",
    "                right_mask = ~left_mask\n",
    "\n",
    "                left_gini = self.gini_index(y[left_mask])\n",
    "                right_gini = self.gini_index(y[right_mask])\n",
    "\n",
    "                weighted_gini = (len(y[left_mask]) / len(y)) * left_gini + (len(y[right_mask]) / len(y)) * right_gini\n",
    "\n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    best_index = col\n",
    "                    best_value = value\n",
    "\n",
    "        return best_index, best_value\n",
    "\n",
    "    def split(self, X, y, index, value):\n",
    "        mask = X[:, index] <= value\n",
    "        return X[mask], y[mask], X[~mask], y[~mask]\n",
    "\n",
    "    def id3(self, X, y, depth):\n",
    "        if depth == 0 or len(np.unique(y)) == 1:\n",
    "            return np.argmax(np.bincount(y))\n",
    "\n",
    "        index, value = self.get_best_split(X, y)\n",
    "\n",
    "        if index is None:\n",
    "            return np.argmax(np.bincount(y))\n",
    "\n",
    "        X_left, y_left, X_right, y_right = self.split(X, y, index, value)\n",
    "\n",
    "        node = {}\n",
    "        node['index'] = index\n",
    "        node['value'] = value\n",
    "        node['left'] = self.id3(X_left, y_left, depth - 1)\n",
    "        node['right'] = self.id3(X_right, y_right, depth - 1)\n",
    "\n",
    "        return node\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            X = X_train.values\n",
    "        else:\n",
    "            X = X_train\n",
    "        if isinstance(y_train, pd.DataFrame):\n",
    "            y = y_train.values\n",
    "        else:\n",
    "            y = y_train\n",
    "        self.tree = self.id3(X, y, self.max_depth)\n",
    "\n",
    "    def predict_instance(self, instance, tree):\n",
    "        if type(tree) != dict:\n",
    "            return tree\n",
    "        if 'value' not in tree:\n",
    "            return tree\n",
    "\n",
    "        value = instance[tree['index']]\n",
    "\n",
    "        if value <= tree['value']:\n",
    "            return self.predict_instance(instance, tree['left'])\n",
    "        else:\n",
    "            return self.predict_instance(instance, tree['right'])\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if isinstance(X_test, pd.DataFrame):\n",
    "            X = X_test.values\n",
    "        else:\n",
    "            X = X_test\n",
    "        predictions = [self.predict_instance(instance, self.tree) for instance in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_my_tree(df, scaler, state, depth):\n",
    "    print(\"Creating model...\")\n",
    "\n",
    "    # Create an instance of LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Convert categorical variables to numerical labels\n",
    "    for column in df_copy.columns:\n",
    "        df_copy[column] = label_encoder.fit_transform(df_copy[column])\n",
    "\n",
    "\n",
    "    # Split the dataset into features (X) and target variable (y)\n",
    "    X = df_copy.drop(TARGET, axis=1)\n",
    "    y = df_copy[TARGET]\n",
    "\n",
    "    # Apply the scaler if provided\n",
    "    if scaler is not None:\n",
    "        scaler = scaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=state)\n",
    "    # Create the Decision Tree model\n",
    "    model = MyDecisionTree(max_depth=depth)\n",
    "    # Fit the model to the data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 0\n",
      "Scaler: None\n",
      "Depth: 3\n",
      "Creating model...\n",
      "Test accuracy: 0.8852392538523925\n",
      "Precision: 0.683377308707124\n",
      "Recall: 0.6137440758293838\n",
      "F1 score: 0.6466916354556804\n",
      "\n",
      "Depth: 4\n",
      "Creating model...\n",
      "Test accuracy: 0.8884833738848338\n",
      "Precision: 0.7194029850746269\n",
      "Recall: 0.5710900473933649\n",
      "F1 score: 0.6367239101717305\n",
      "\n",
      "Depth: 5\n",
      "Creating model...\n",
      "Test accuracy: 0.8880778588807786\n",
      "Precision: 0.7354838709677419\n",
      "Recall: 0.5402843601895735\n",
      "F1 score: 0.6229508196721312\n",
      "\n",
      "Depth: 6\n",
      "Creating model...\n",
      "Test accuracy: 0.8917274939172749\n",
      "Precision: 0.7540983606557377\n",
      "Recall: 0.5450236966824644\n",
      "F1 score: 0.6327372764786794\n",
      "\n",
      "Scaler: MinMaxScaler\n",
      "Depth: 3\n",
      "Creating model...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m model, X_test, y_test \u001b[38;5;241m=\u001b[39m create_my_tree(df, scaler, state, depth)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Predict the labels for the test set\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Calculate the accuracy score\u001b[39;00m\n\u001b[1;32m     15\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "Cell \u001b[0;32mIn[65], line 92\u001b[0m, in \u001b[0;36mMyDecisionTree.predict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_test):\n\u001b[0;32m---> 92\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n\u001b[1;32m     93\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_instance(instance, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree) \u001b[38;5;28;01mfor\u001b[39;00m instance \u001b[38;5;129;01min\u001b[39;00m X]\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(predictions)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "average_accuracy = [[], [], [], []]\n",
    "average_precision = [[], [], [], []]\n",
    "average_recall = [[], [], [], []]\n",
    "average_f1 = [[], [], [], []]\n",
    "for state in RANDOM_STATES:\n",
    "    print(f\"Random state: {state}\")\n",
    "    for i, scaler in enumerate(SCALERS):\n",
    "        print(f\"Scaler: {scaler.__name__ if scaler is not None else None}\")\n",
    "        for depth in range(3,7):\n",
    "            print(f\"Depth: {depth}\")\n",
    "            model, X_test, y_test = create_my_tree(df, scaler, state, depth)\n",
    "            # Predict the labels for the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "            # Calculate the accuracy score\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            print(f'Test accuracy: {accuracy}')\n",
    "            print(f'Precision: {precision}')\n",
    "            print(f'Recall: {recall}')\n",
    "            print(f'F1 score: {f1}\\n')\n",
    "\n",
    "            average_accuracy[i].append(accuracy)\n",
    "            average_precision[i].append(precision)\n",
    "            average_recall[i].append(recall)\n",
    "            average_f1[i].append(f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler: None\n",
      "Variance of accuracy: 8.060309585874805e-05\n",
      "Variance of precision: 0.0\n",
      "Variance of recall: 0.0\n",
      "Variance of F1 score: 0.0\n",
      "\n",
      "Average accuracy: 0.8439578264395783\n",
      "Average precision: 0.0\n",
      "Average recall: 0.0\n",
      "Average F1 score: 0.0\n",
      "\n",
      "Scaler: MinMaxScaler\n",
      "Variance of accuracy: 8.060309585874805e-05\n",
      "Variance of precision: 0.0\n",
      "Variance of recall: 0.0\n",
      "Variance of F1 score: 0.0\n",
      "\n",
      "Average accuracy: 0.8439578264395783\n",
      "Average precision: 0.0\n",
      "Average recall: 0.0\n",
      "Average F1 score: 0.0\n",
      "\n",
      "Scaler: StandardScaler\n",
      "Variance of accuracy: 8.060309585874805e-05\n",
      "Variance of precision: 0.0\n",
      "Variance of recall: 0.0\n",
      "Variance of F1 score: 0.0\n",
      "\n",
      "Average accuracy: 0.8439578264395783\n",
      "Average precision: 0.0\n",
      "Average recall: 0.0\n",
      "Average F1 score: 0.0\n",
      "\n",
      "Scaler: RobustScaler\n",
      "Variance of accuracy: 8.060309585874805e-05\n",
      "Variance of precision: 0.0\n",
      "Variance of recall: 0.0\n",
      "Variance of F1 score: 0.0\n",
      "\n",
      "Average accuracy: 0.8439578264395783\n",
      "Average precision: 0.0\n",
      "Average recall: 0.0\n",
      "Average F1 score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, scaler in enumerate(SCALERS):\n",
    "    print(f\"Scaler: {scaler.__name__ if scaler is not None else None}\")\n",
    "\n",
    "    print(f'Variance of accuracy: {np.var(average_accuracy[i])}')\n",
    "    print(f'Variance of precision: {np.var(average_precision[i])}')\n",
    "    print(f'Variance of recall: {np.var(average_recall[i])}')\n",
    "    print(f'Variance of F1 score: {np.var(average_f1[i])}\\n')\n",
    "\n",
    "    print(f'Average accuracy: {np.mean(average_accuracy[i])}')\n",
    "    print(f'Average precision: {np.mean(average_precision[i])}')\n",
    "    print(f'Average recall: {np.mean(average_recall[i])}')\n",
    "    print(f'Average F1 score: {np.mean(average_f1[i])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
