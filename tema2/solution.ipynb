{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATT_INT = [\"Administrative\", \"Informational\", \"ProductRelated\", \"OperatingSystems\", \"Browser\", \"Region\", \"TrafficType\"]\n",
    "ATT_FLOAT = [\"Administrative_Duration\", \"Informational_Duration\", \"ProductRelated_Duration\", \"BounceRates\", \"ExitRates\", \"PageValues\", \"SpecialDay\"]\n",
    "ATT_STRING = [\"Month\", \"VisitorType\"]\n",
    "ATT_BOOL = [\"Weekend\", \"Revenue\"]\n",
    "\n",
    "TARGET = \"Revenue\"\n",
    "\n",
    "RANDOM_STATES = [0, 1, 5, 7, 13, 23, 29, 32, 37, 42]\n",
    "\n",
    "SCALERS = [None, MinMaxScaler, StandardScaler, RobustScaler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Count the number of occurrences of each class\n",
    "class_counts = df[TARGET].value_counts()\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Revenue')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresie Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(df, scaler, state):\n",
    "    print(\"Creating model...\")\n",
    "    # Create the logistic regression model\n",
    "    model = LogisticRegression(max_iter=df.shape[0])\n",
    "    # Create an instance of LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Convert categorical variables to numerical labels\n",
    "    for column in df_copy.columns:\n",
    "        df_copy[column] = label_encoder.fit_transform(df_copy[column])\n",
    "\n",
    "\n",
    "    # Split the dataset into features (X) and target variable (y)\n",
    "    X = df_copy.drop(TARGET, axis=1)\n",
    "    y = df_copy[TARGET]\n",
    "\n",
    "    # # Apply the scaler if provided\n",
    "    if scaler is not None:\n",
    "        scaler = scaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=state)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_simple, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Predict the labels for the test set\u001b[39;00m\n\u001b[1;32m      3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model_simple\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[0;32mIn[19], line 29\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(df, scaler, state)\u001b[0m\n\u001b[1;32m     26\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.20\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mstate)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Fit the model to the data\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, X_test, y_test\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1303\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1301\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1303\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:452\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    448\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[1;32m    449\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[1;32m    450\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[1;32m    451\u001b[0m ]\n\u001b[0;32m--> 452\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    461\u001b[0m     solver,\n\u001b[1;32m    462\u001b[0m     opt_res,\n\u001b[1;32m    463\u001b[0m     max_iter,\n\u001b[1;32m    464\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[1;32m    465\u001b[0m )\n\u001b[1;32m    466\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:365\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    359\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 71\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/linear_model/_linear_loss.py:292\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    290\u001b[0m     grad[:n_features] \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m grad_pointwise \u001b[38;5;241m+\u001b[39m l2_reg_strength \u001b[38;5;241m*\u001b[39m weights\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept:\n\u001b[0;32m--> 292\u001b[0m         grad[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_pointwise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m     grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((n_classes, n_dof), dtype\u001b[38;5;241m=\u001b[39mweights\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/_methods.py:47\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model_simple, X_test, y_test = create_model(df, None, 42)\n",
    "# Predict the labels for the test set\n",
    "y_pred = model_simple.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 0\n",
      "Scaler: None\n",
      "Creating model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8811841038118411\n",
      "Precision: 0.7328519855595668\n",
      "Recall: 0.48104265402843605\n",
      "F1 score: 0.580829756795422\n",
      "\n",
      "Scaler: MinMaxScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8815896188158961\n",
      "Precision: 0.7407407407407407\n",
      "Recall: 0.47393364928909953\n",
      "F1 score: 0.5780346820809248\n",
      "\n",
      "Scaler: StandardScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8811841038118411\n",
      "Precision: 0.7362637362637363\n",
      "Recall: 0.476303317535545\n",
      "F1 score: 0.5784172661870504\n",
      "\n",
      "Scaler: RobustScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8815896188158961\n",
      "Precision: 0.7389705882352942\n",
      "Recall: 0.476303317535545\n",
      "F1 score: 0.5792507204610952\n",
      "\n",
      "Random state: 1\n",
      "Scaler: None\n",
      "Creating model...\n",
      "Test accuracy: 0.8961881589618816\n",
      "Precision: 0.6907630522088354\n",
      "Recall: 0.49002849002849\n",
      "F1 score: 0.5733333333333333\n",
      "\n",
      "Scaler: MinMaxScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8969991889699919\n",
      "Precision: 0.691699604743083\n",
      "Recall: 0.4985754985754986\n",
      "F1 score: 0.5794701986754967\n",
      "\n",
      "Scaler: StandardScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8969991889699919\n",
      "Precision: 0.691699604743083\n",
      "Recall: 0.4985754985754986\n",
      "F1 score: 0.5794701986754967\n",
      "\n",
      "Scaler: RobustScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.897404703974047\n",
      "Precision: 0.6929133858267716\n",
      "Recall: 0.5014245014245015\n",
      "F1 score: 0.5818181818181818\n",
      "\n",
      "Random state: 5\n",
      "Scaler: None\n",
      "Creating model...\n",
      "Test accuracy: 0.8917274939172749\n",
      "Precision: 0.6963562753036437\n",
      "Recall: 0.4725274725274725\n",
      "F1 score: 0.5630114566284778\n",
      "\n",
      "Scaler: MinMaxScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8884833738848338\n",
      "Precision: 0.6772908366533864\n",
      "Recall: 0.46703296703296704\n",
      "F1 score: 0.5528455284552846\n",
      "\n",
      "Scaler: StandardScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8901054339010543\n",
      "Precision: 0.6837944664031621\n",
      "Recall: 0.47527472527472525\n",
      "F1 score: 0.5607779578606158\n",
      "\n",
      "Scaler: RobustScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8901054339010543\n",
      "Precision: 0.6837944664031621\n",
      "Recall: 0.47527472527472525\n",
      "F1 score: 0.5607779578606158\n",
      "\n",
      "Random state: 7\n",
      "Scaler: None\n",
      "Creating model...\n",
      "Test accuracy: 0.8896999188969992\n",
      "Precision: 0.7174721189591078\n",
      "Recall: 0.4961439588688946\n",
      "F1 score: 0.5866261398176292\n",
      "\n",
      "Scaler: MinMaxScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8901054339010543\n",
      "Precision: 0.7251908396946565\n",
      "Recall: 0.4884318766066838\n",
      "F1 score: 0.5837173579109064\n",
      "\n",
      "Scaler: StandardScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8905109489051095\n",
      "Precision: 0.7245283018867924\n",
      "Recall: 0.493573264781491\n",
      "F1 score: 0.5871559633027523\n",
      "\n",
      "Scaler: RobustScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8909164639091647\n",
      "Precision: 0.7272727272727273\n",
      "Recall: 0.493573264781491\n",
      "F1 score: 0.5880551301684533\n",
      "\n",
      "Random state: 13\n",
      "Scaler: None\n",
      "Creating model...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, scaler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(SCALERS):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScaler: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscaler\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mscaler\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     model, X_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Predict the labels for the test set\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[0;32mIn[104], line 30\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(df, scaler, state)\u001b[0m\n\u001b[1;32m     26\u001b[0m     X \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and test sets\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Fit the model to the data\u001b[39;00m\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2672\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2668\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m   2670\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m-> 2672\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_iterable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2674\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\n\u001b[1;32m   2675\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2674\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2668\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m   2670\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m   2672\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2673\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m-> 2674\u001b[0m         (_safe_indexing(a, train), \u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2675\u001b[0m     )\n\u001b[1;32m   2676\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/__init__.py:353\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    348\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying the columns using strings is only supported for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas DataFrames\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    350\u001b[0m     )\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pandas_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/__init__.py:195\u001b[0m, in \u001b[0;36m_pandas_indexing\u001b[0;34m(X, key, key_dtype, axis)\u001b[0m\n\u001b[1;32m    190\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(key)):\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# using take() instead of iloc[] ensures the return value is a \"proper\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# copy that will not raise SettingWithCopyWarning\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# check whether we should index with loc or iloc\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc \u001b[38;5;28;01mif\u001b[39;00m key_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mloc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:4068\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4063\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4064\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4065\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4066\u001b[0m     )\n\u001b[0;32m-> 4068\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4070\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4072\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4074\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4075\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:877\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    874\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    876\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 877\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:670\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    663\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    664\u001b[0m         indexer,\n\u001b[1;32m    665\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    666\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    667\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    668\u001b[0m     )\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    671\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    672\u001b[0m             indexer,\n\u001b[1;32m    673\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    674\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    675\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    676\u001b[0m             ),\n\u001b[1;32m    677\u001b[0m         )\n\u001b[1;32m    678\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    679\u001b[0m     ]\n\u001b[1;32m    681\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    682\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/managers.py:671\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    663\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    664\u001b[0m         indexer,\n\u001b[1;32m    665\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    666\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    667\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    668\u001b[0m     )\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    670\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 671\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    678\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    679\u001b[0m     ]\n\u001b[1;32m    681\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    682\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/blocks.py:1061\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m-> 1061\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/array_algos/take.py:118\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[1;32m    117\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/array_algos/take.py:163\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    158\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    160\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    161\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[1;32m    162\u001b[0m )\n\u001b[0;32m--> 163\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[1;32m    166\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "average_accuracy = [[], [], [], []]\n",
    "average_precision = [[], [], [], []]\n",
    "average_recall = [[], [], [], []]\n",
    "average_f1 = [[], [], [], []]\n",
    "for state in RANDOM_STATES:\n",
    "    print(f\"Random state: {state}\")\n",
    "    for i, scaler in enumerate(SCALERS):\n",
    "        print(f\"Scaler: {scaler.__name__ if scaler is not None else None}\")\n",
    "        model, X_test, y_test = create_model(df, scaler, state)\n",
    "        # Predict the labels for the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate the accuracy score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(f'Test accuracy: {accuracy}')\n",
    "        print(f'Precision: {precision}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'F1 score: {f1}\\n')\n",
    "\n",
    "        average_accuracy[i].append(accuracy)\n",
    "        average_precision[i].append(precision)\n",
    "        average_recall[i].append(recall)\n",
    "        average_f1[i].append(f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler: None\n",
      "Variance of accuracy: 6.75463678287484e-05\n",
      "Variance of precision: 0.0003387872804146401\n",
      "Variance of recall: 0.0004964467360682445\n",
      "Variance of F1 score: 0.0003995725806428393\n",
      "\n",
      "Average accuracy: 0.8796431467964314\n",
      "Average precision: 0.7239139649274141\n",
      "Average recall: 0.3707234513110739\n",
      "Average F1 score: 0.4898631981356507\n",
      "\n",
      "Scaler: MinMaxScaler\n",
      "Variance of accuracy: 8.183312514923135e-05\n",
      "Variance of precision: 0.0006859716135845494\n",
      "Variance of recall: 0.0003406622085245759\n",
      "Variance of F1 score: 0.0003955898838534125\n",
      "\n",
      "Average accuracy: 0.872911597729116\n",
      "Average precision: 0.7630925031037783\n",
      "Average recall: 0.27069720940128245\n",
      "Average F1 score: 0.39912146035271423\n",
      "\n",
      "Scaler: StandardScaler\n",
      "Variance of accuracy: 6.807258356799275e-05\n",
      "Variance of precision: 0.0003105376684585742\n",
      "Variance of recall: 0.0004890320432341643\n",
      "Variance of F1 score: 0.0003876774311576844\n",
      "\n",
      "Average accuracy: 0.8812652068126521\n",
      "Average precision: 0.7390433840393512\n",
      "Average recall: 0.37065794235241617\n",
      "Average F1 score: 0.49323600318769223\n",
      "\n",
      "Scaler: RobustScaler\n",
      "Variance of accuracy: 6.966438617920698e-05\n",
      "Variance of precision: 0.0003471223087188798\n",
      "Variance of recall: 0.0005199377535854273\n",
      "Variance of F1 score: 0.00041765881610389774\n",
      "\n",
      "Average accuracy: 0.8813463098134632\n",
      "Average precision: 0.7390851223965123\n",
      "Average recall: 0.3714541246950055\n",
      "Average F1 score: 0.49393287938682395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, scaler in enumerate(SCALERS):\n",
    "    print(f\"Scaler: {scaler.__name__ if scaler is not None else None}\")\n",
    "\n",
    "    print(f'Variance of accuracy: {np.var(average_accuracy[i])}')\n",
    "    print(f'Variance of precision: {np.var(average_precision[i])}')\n",
    "    print(f'Variance of recall: {np.var(average_recall[i])}')\n",
    "    print(f'Variance of F1 score: {np.var(average_f1[i])}\\n')\n",
    "\n",
    "    print(f'Average accuracy: {np.mean(average_accuracy[i])}')\n",
    "    print(f'Average precision: {np.mean(average_precision[i])}')\n",
    "    print(f'Average recall: {np.mean(average_recall[i])}')\n",
    "    print(f'Average F1 score: {np.mean(average_f1[i])}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "class MyLogisticRegression:\n",
    "    def __init__(self, lr=.01, epochs_no=100):\n",
    "        self.lr = lr\n",
    "        self.epochs_no = epochs_no\n",
    "        self.W = None\n",
    "\n",
    "    def nll(self, Y, T):\n",
    "        return -np.sum(T * np.log(Y) + (1 - T) * np.log(1 - Y))\n",
    "\n",
    "    def train(self, X, T):\n",
    "        (N, D) = X.shape\n",
    "        X_hat = np.concatenate([X, np.ones((N, 1))], axis=1)\n",
    "        W = np.random.randn((D+1))\n",
    "\n",
    "        for _ in range(self.epochs_no):\n",
    "            W = W - X_hat.T @ (expit(X_hat @ W) - T) * self.lr / N\n",
    "        self.W =  W\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = expit(np.concatenate([X, np.ones((X.shape[0], 1))], axis=1) @ self.W)\n",
    "        for i in range(len(y)):\n",
    "            if y[i] >= 0.5:\n",
    "                y[i] = 1\n",
    "            else:\n",
    "                y[i] = 0\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_my_model(df, scaler, state):\n",
    "    print(\"Creating model...\")\n",
    "    # Create the logistic regression model\n",
    "    model = MyLogisticRegression(lr=.01, epochs_no=1000)\n",
    "    # Create an instance of LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Convert categorical variables to numerical labels\n",
    "    for column in df_copy.columns:\n",
    "        df_copy[column] = label_encoder.fit_transform(df_copy[column])\n",
    "\n",
    "\n",
    "    # Split the dataset into features (X) and target variable (y)\n",
    "    X = df_copy.drop(TARGET, axis=1)\n",
    "    y = df_copy[TARGET]\n",
    "\n",
    "    # # Apply the scaler if provided\n",
    "    if scaler is not None:\n",
    "        scaler = scaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=state)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    model.train(X_train, y_train)\n",
    "\n",
    "    return model, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 42\n",
      "Scaler: None\n",
      "Creating model...\n",
      "Test accuracy: 0.8029197080291971\n",
      "Precision: 0.4487004103967168\n",
      "Recall: 0.7980535279805353\n",
      "F1 score: 0.574430823117338\n",
      "\n",
      "Scaler: MinMaxScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.82441200324412\n",
      "Precision: 0.21052631578947367\n",
      "Recall: 0.019464720194647202\n",
      "F1 score: 0.035634743875278395\n",
      "\n",
      "Scaler: StandardScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8195458231954582\n",
      "Precision: 0.4681647940074906\n",
      "Recall: 0.6082725060827251\n",
      "F1 score: 0.5291005291005291\n",
      "\n",
      "Scaler: RobustScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8272506082725061\n",
      "Precision: 0.4883720930232558\n",
      "Recall: 0.7664233576642335\n",
      "F1 score: 0.5965909090909092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = [[], [], [], []]\n",
    "average_precision = [[], [], [], []]\n",
    "average_recall = [[], [], [], []]\n",
    "average_f1 = [[], [], [], []]\n",
    "for state in [42]:\n",
    "    print(f\"Random state: {state}\")\n",
    "    for i, scaler in enumerate(SCALERS):\n",
    "        print(f\"Scaler: {scaler.__name__ if scaler is not None else None}\")\n",
    "        model, X_test, y_test = create_my_model(df, scaler, state)\n",
    "        # Predict the labels for the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Calculate the accuracy score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(f'Test accuracy: {accuracy}')\n",
    "        print(f'Precision: {precision}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'F1 score: {f1}\\n')\n",
    "\n",
    "        average_accuracy[i].append(accuracy)\n",
    "        average_precision[i].append(precision)\n",
    "        average_recall[i].append(recall)\n",
    "        average_f1[i].append(f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbori de decizize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def create_decision_tree_model(df, scaler, state, depth):\n",
    "    print(\"Creating model...\")\n",
    "    # Create the logistic regression model\n",
    "\n",
    "\n",
    "\n",
    "    # Create an instance of LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Convert categorical variables to numerical labels\n",
    "    for column in df_copy.columns:\n",
    "        df_copy[column] = label_encoder.fit_transform(df_copy[column])\n",
    "\n",
    "\n",
    "    # Split the dataset into features (X) and target variable (y)\n",
    "    X = df_copy.drop(TARGET, axis=1)\n",
    "    y = df_copy[TARGET]\n",
    "\n",
    "    # # Apply the scaler if provided\n",
    "    if scaler is not None:\n",
    "        scaler = scaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=state)\n",
    "\n",
    "    # Create an instance of DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier(random_state=state, max_depth=depth)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    return clf, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "Test accuracy: 0.8864557988645579\n",
      "Test accuracy: 0.8864557988645579\n",
      "Precision: 0.6955223880597015\n",
      "Recall: 0.5669099756690997\n",
      "F1 score: 0.6246648793565683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, X_test, y_test = create_decision_tree_model(df, None, 42, 6)\n",
    "# Predict the labels for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Test accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 score: {f1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state: 42\n",
      "Scaler: None\n",
      "Creating model...\n",
      "Test accuracy: 0.856853203568532\n",
      "Precision: 0.5700483091787439\n",
      "Recall: 0.5742092457420924\n",
      "F1 score: 0.572121212121212\n",
      "\n",
      "Scaler: MinMaxScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8572587185725872\n",
      "Precision: 0.5714285714285714\n",
      "Recall: 0.5742092457420924\n",
      "F1 score: 0.5728155339805825\n",
      "\n",
      "Scaler: StandardScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.8552311435523114\n",
      "Precision: 0.5652173913043478\n",
      "Recall: 0.5693430656934306\n",
      "F1 score: 0.5672727272727273\n",
      "\n",
      "Scaler: RobustScaler\n",
      "Creating model...\n",
      "Test accuracy: 0.856853203568532\n",
      "Precision: 0.5700483091787439\n",
      "Recall: 0.5742092457420924\n",
      "F1 score: 0.572121212121212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "average_accuracy = [[], [], [], []]\n",
    "average_precision = [[], [], [], []]\n",
    "average_recall = [[], [], [], []]\n",
    "average_f1 = [[], [], [], []]\n",
    "for state in [42]:\n",
    "    print(f\"Random state: {state}\")\n",
    "    for i, scaler in enumerate(SCALERS):\n",
    "        print(f\"Scaler: {scaler.__name__ if scaler is not None else None}\")\n",
    "        model, X_test, y_test = create_decision_tree_model(df, scaler, state)\n",
    "        # Predict the labels for the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Calculate the accuracy score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        print(f'Test accuracy: {accuracy}')\n",
    "        print(f'Precision: {precision}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'F1 score: {f1}\\n')\n",
    "\n",
    "        average_accuracy[i].append(accuracy)\n",
    "        average_precision[i].append(precision)\n",
    "        average_recall[i].append(recall)\n",
    "        average_f1[i].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTree:\n",
    "    def __init__(self):\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.build_tree(X, y)\n",
    "\n",
    "    def build_tree(self, X, y):\n",
    "        # Stopping condition: check if all samples belong to the same class\n",
    "        if len(set(y)) == 1:\n",
    "            return {'class': y[0]}\n",
    "\n",
    "        # Stopping condition: check if there are no more attributes to split on\n",
    "        if len(X[0]) == 0:\n",
    "            return {'class': self.get_majority_class(y)}\n",
    "\n",
    "        # Find the best attribute and value to split on\n",
    "        best_attr, best_value = self.find_best_split(X, y)\n",
    "\n",
    "        # Split the data based on the best attribute and value\n",
    "        left_X, left_y, right_X, right_y = self.split_data(X, y, best_attr, best_value)\n",
    "\n",
    "        # Recursively build the left and right subtrees\n",
    "        left_subtree = self.build_tree(left_X, left_y)\n",
    "        right_subtree = self.build_tree(right_X, right_y)\n",
    "\n",
    "        # Create a node for the best split\n",
    "        node = {'attribute': best_attr, 'value': best_value, 'left': left_subtree, 'right': right_subtree}\n",
    "\n",
    "        return node\n",
    "\n",
    "    def find_best_split(self, X, y):\n",
    "        best_attr = None\n",
    "        best_value = None\n",
    "        best_score = float('-inf')\n",
    "\n",
    "        # Iterate over each attribute and its values\n",
    "        for attr in range(len(X[0])):\n",
    "            for value in set(X[:, attr]):\n",
    "                # Split the data based on the attribute and value\n",
    "                left_X, left_y, right_X, right_y = self.split_data(X, y, attr, value)\n",
    "\n",
    "                # Calculate the information gain or Gini index\n",
    "                score = self.calculate_score(left_y, right_y)\n",
    "\n",
    "                # Update the best split if the score is higher\n",
    "                if score > best_score:\n",
    "                    best_attr = attr\n",
    "                    best_value = value\n",
    "                    best_score = score\n",
    "\n",
    "        return best_attr, best_value\n",
    "\n",
    "    def split_data(self, X, y, attr, value):\n",
    "        left_X = []\n",
    "        left_y = []\n",
    "        right_X = []\n",
    "        right_y = []\n",
    "\n",
    "        # Split the data based on the attribute and value\n",
    "        for i in range(len(X)):\n",
    "            if X[i][attr] == value:\n",
    "                left_X.append(X[i])\n",
    "                left_y.append(y[i])\n",
    "            else:\n",
    "                right_X.append(X[i])\n",
    "                right_y.append(y[i])\n",
    "\n",
    "        return np.array(left_X), np.array(left_y), np.array(right_X), np.array(right_y)\n",
    "\n",
    "    def calculate_score(self, left_y, right_y):\n",
    "        # Calculate the information gain or Gini index\n",
    "        # Implement your own calculation method here\n",
    "        # Return the score\n",
    "         # count all samples at split point\n",
    "        # Calculate the Gini index for a split dataset\n",
    "\n",
    "        # count all samples at split point\n",
    "        n_instances = float(sum([len(group) for group in groups]))\n",
    "        # sum weighted Gini index for each group\n",
    "        gini = 0.0\n",
    "        for group in groups:\n",
    "            size = float(len(group))\n",
    "            # avoid divide by zero\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "            # score the group based on the score for each class\n",
    "            for class_val in classes:\n",
    "                p = [row[-1] for row in group].count(class_val) / size\n",
    "                score += p * p\n",
    "            # weight the group score by its relative size\n",
    "            gini += (1.0 - score) * (size / n_instances)\n",
    "        return gini\n",
    "\n",
    "    def get_majority_class(self, y):\n",
    "        # Get the majority class in the target variable\n",
    "        # Implement your own method here\n",
    "        # Return the majority class\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "\n",
    "        # Traverse the tree and make predictions for each sample\n",
    "        for sample in X:\n",
    "            prediction = self.traverse_tree(sample, self.tree)\n",
    "            predictions.append(prediction)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def traverse_tree(self, sample, node):\n",
    "        # Base case: check if the node is a leaf node\n",
    "        if 'class' in node:\n",
    "            return node['class']\n",
    "\n",
    "        # Get the attribute and value of the current node\n",
    "        attr = node['attribute']\n",
    "        value = node['value']\n",
    "\n",
    "        # Traverse the left or right subtree based on the attribute value of the sample\n",
    "        if sample[attr] == value:\n",
    "            return self.traverse_tree(sample, node['left'])\n",
    "        else:\n",
    "            return self.traverse_tree(sample, node['right'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "print(df[TARGET].)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
