{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from scipy.stats import pointbiserialr, chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATT_INT = [\"Administrative\", \"Informational\", \"ProductRelated\"]\n",
    "ATT_INT_CATEGORY = [\"OperatingSystems\", \"Browser\", \"Region\", \"TrafficType\"]\n",
    "ATT_FLOAT = [\n",
    "    \"Administrative_Duration\",\n",
    "    \"Informational_Duration\",\n",
    "    \"ProductRelated_Duration\",\n",
    "    \"BounceRates\",\n",
    "    \"ExitRates\",\n",
    "    \"PageValues\",\n",
    "    \"SpecialDay\",\n",
    "]\n",
    "ATT_STRING = [\"Month\", \"VisitorType\"]\n",
    "ATT_BOOL = [\"Weekend\", \"Revenue\"]\n",
    "ATT_BOOL_NO_TARGET = [\"Weekend\"]\n",
    "\n",
    "TARGET = \"Revenue\"\n",
    "\n",
    "RANDOM_STATES = [0, 1, 5, 7, 13, 23, 29, 32, 37, 42]\n",
    "\n",
    "SCALERS = [None, MinMaxScaler, StandardScaler, RobustScaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic(states, scalers, constructor, filename):\n",
    "    if filename is not None:\n",
    "        if os.path.exists(filename):\n",
    "            print(f\"Loading data from {filename}\")\n",
    "\n",
    "            # Load the data from the file\n",
    "            with open(filename, \"rb\") as f:\n",
    "                (\n",
    "                    average_accuracy,\n",
    "                    average_precision,\n",
    "                    average_recall,\n",
    "                    average_f1,\n",
    "                ) = pickle.load(f)\n",
    "            return average_accuracy, average_precision, average_recall, average_f1\n",
    "\n",
    "    average_accuracy = [[], [], [], []]\n",
    "    average_precision = [[], [], [], []]\n",
    "    average_recall = [[], [], [], []]\n",
    "    average_f1 = [[], [], [], []]\n",
    "    for state in states:\n",
    "        print(f\"Random state: {state}\")\n",
    "        for i, scaler in enumerate(scalers):\n",
    "            print(f\"Scaler: {scaler.__name__ if scaler is not None else None}\")\n",
    "            model, X_test, y_test = constructor(df, scaler, state)\n",
    "            # Predict the labels for the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Calculate the accuracy score\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "            print(f\"Test accuracy: {accuracy}\")\n",
    "            print(f\"Precision: {precision}\")\n",
    "            print(f\"Recall: {recall}\")\n",
    "            print(f\"F1 score: {f1}\\n\")\n",
    "\n",
    "            average_accuracy[i].append(accuracy)\n",
    "            average_precision[i].append(precision)\n",
    "            average_recall[i].append(recall)\n",
    "            average_f1[i].append(f1)\n",
    "\n",
    "    # Save the average lists to a file\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(\n",
    "            (average_accuracy, average_precision, average_recall, average_f1), f\n",
    "        )\n",
    "    return average_accuracy, average_precision, average_recall, average_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_variance(\n",
    "    average_accuracy, average_precision, average_recall, average_f1\n",
    "):\n",
    "    avgs_variances = []\n",
    "    for i, scaler in enumerate(SCALERS):\n",
    "        print(f\"Scaler: {scaler.__name__ if scaler is not None else None}\")\n",
    "\n",
    "        variance_accuracy = np.var(average_accuracy[i])\n",
    "        variance_precision = np.var(average_precision[i])\n",
    "        variance_recall = np.var(average_recall[i])\n",
    "        variance_f1 = np.var(average_f1[i])\n",
    "\n",
    "        print(f\"Variance of accuracy: {variance_accuracy}\")\n",
    "        print(f\"Variance of precision: {variance_precision}\")\n",
    "        print(f\"Variance of recall: {variance_recall}\")\n",
    "        print(f\"Variance of F1 score: {variance_f1}\\n\")\n",
    "\n",
    "        avg_accuracy = np.mean(average_accuracy[i])\n",
    "        avg_precision = np.mean(average_precision[i])\n",
    "        avg_recall = np.mean(average_recall[i])\n",
    "        avg_f1 = np.mean(average_f1[i])\n",
    "\n",
    "        print(f\"Average accuracy: {avg_accuracy}\")\n",
    "        print(f\"Average precision: {avg_precision}\")\n",
    "        print(f\"Average recall: {avg_recall}\")\n",
    "        print(f\"Average F1 score: {avg_f1}\\n\")\n",
    "        values = (\n",
    "            avg_accuracy,\n",
    "            avg_precision,\n",
    "            avg_recall,\n",
    "            avg_f1,\n",
    "            variance_accuracy,\n",
    "            variance_precision,\n",
    "            variance_recall,\n",
    "            variance_f1,\n",
    "        )\n",
    "        avgs_variances.append(values)\n",
    "    return avgs_variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(df, scaler, state):\n",
    "    print(\"Creating model...\")\n",
    "    # Create the logistic regression model\n",
    "    model = LogisticRegression(max_iter=df.shape[0])\n",
    "    # Create an instance of LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Convert categorical variables to numerical labels\n",
    "    for column in df_copy.columns:\n",
    "        df_copy[column] = label_encoder.fit_transform(df_copy[column])\n",
    "\n",
    "    # Split the dataset into features (X) and target variable (y)\n",
    "    X = df_copy.drop(TARGET, axis=1)\n",
    "    y = df_copy[TARGET]\n",
    "\n",
    "    # # Apply the scaler if provided\n",
    "    if scaler is not None:\n",
    "        scaler = scaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=state\n",
    "    )\n",
    "\n",
    "    # Fit the model to the data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "Test accuracy: 0.8807785888077859\n"
     ]
    }
   ],
   "source": [
    "model_simple, X_test, y_test = create_model(df, None, 42)\n",
    "# Predict the labels for the test set\n",
    "y_pred = model_simple.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from logistic.pkl\n"
     ]
    }
   ],
   "source": [
    "average_accuracy, average_precision, average_recall, average_f1 = run_logistic(\n",
    "    RANDOM_STATES, SCALERS, create_model, \"logistic.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler: None\n",
      "Variance of accuracy: 4.5787347010995934e-05\n",
      "Variance of precision: 0.0005192577084399036\n",
      "Variance of recall: 0.00038491417123306997\n",
      "Variance of F1 score: 0.00019789123622821324\n",
      "\n",
      "Average accuracy: 0.8963503649635036\n",
      "Average precision: 0.6924849532392865\n",
      "Average recall: 0.6052713318709566\n",
      "Average F1 score: 0.6455573528748052\n",
      "\n",
      "Scaler: MinMaxScaler\n",
      "Variance of accuracy: 4.314311292129322e-05\n",
      "Variance of precision: 0.0004166265028214939\n",
      "Variance of recall: 0.0002322291488033874\n",
      "Variance of F1 score: 0.00013234754447677942\n",
      "\n",
      "Average accuracy: 0.8952960259529602\n",
      "Average precision: 0.6930091221882309\n",
      "Average recall: 0.5916614299187041\n",
      "Average F1 score: 0.6380548969181421\n",
      "\n",
      "Scaler: StandardScaler\n",
      "Variance of accuracy: 3.9933196911903204e-05\n",
      "Variance of precision: 0.0003755323441311471\n",
      "Variance of recall: 0.0002438391575655118\n",
      "Variance of F1 score: 0.00010917547439038542\n",
      "\n",
      "Average accuracy: 0.8952149229521492\n",
      "Average precision: 0.6924595968063515\n",
      "Average recall: 0.591951497715859\n",
      "Average F1 score: 0.6379686959479371\n",
      "\n",
      "Scaler: RobustScaler\n",
      "Variance of accuracy: 5.013684898068731e-05\n",
      "Variance of precision: 0.0005074785469591962\n",
      "Variance of recall: 0.00037943480175537227\n",
      "Variance of F1 score: 0.00017410182285837458\n",
      "\n",
      "Average accuracy: 0.8949310624493105\n",
      "Average precision: 0.6909772230709689\n",
      "Average recall: 0.5926844755277483\n",
      "Average F1 score: 0.637648150286428\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.8963503649635036,\n",
       "  0.6924849532392865,\n",
       "  0.6052713318709566,\n",
       "  0.6455573528748052,\n",
       "  4.5787347010995934e-05,\n",
       "  0.0005192577084399036,\n",
       "  0.00038491417123306997,\n",
       "  0.00019789123622821324),\n",
       " (0.8952960259529602,\n",
       "  0.6930091221882309,\n",
       "  0.5916614299187041,\n",
       "  0.6380548969181421,\n",
       "  4.314311292129322e-05,\n",
       "  0.0004166265028214939,\n",
       "  0.0002322291488033874,\n",
       "  0.00013234754447677942),\n",
       " (0.8952149229521492,\n",
       "  0.6924595968063515,\n",
       "  0.591951497715859,\n",
       "  0.6379686959479371,\n",
       "  3.9933196911903204e-05,\n",
       "  0.0003755323441311471,\n",
       "  0.0002438391575655118,\n",
       "  0.00010917547439038542),\n",
       " (0.8949310624493105,\n",
       "  0.6909772230709689,\n",
       "  0.5926844755277483,\n",
       "  0.637648150286428,\n",
       "  5.013684898068731e-05,\n",
       "  0.0005074785469591962,\n",
       "  0.00037943480175537227,\n",
       "  0.00017410182285837458)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_average_variance(\n",
    "    average_accuracy, average_precision, average_recall, average_f1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "\n",
    "class MyLogisticRegression:\n",
    "    def __init__(self, lr=0.01, epochs_no=100):\n",
    "        self.lr = lr\n",
    "        self.epochs_no = epochs_no\n",
    "        self.W = None\n",
    "\n",
    "    def nll(self, Y, T):\n",
    "        return -np.sum(T * np.log(Y) + (1 - T) * np.log(1 - Y))\n",
    "\n",
    "    def train(self, X, T):\n",
    "        (N, D) = X.shape\n",
    "        X_hat = np.concatenate([X, np.ones((N, 1))], axis=1)\n",
    "        W = np.random.randn((D + 1))\n",
    "\n",
    "        for _ in range(self.epochs_no):\n",
    "            W = W - X_hat.T @ (expit(X_hat @ W) - T) * self.lr / N\n",
    "        self.W = W\n",
    "\n",
    "    def predict(self, X):\n",
    "        y = expit(np.concatenate([X, np.ones((X.shape[0], 1))], axis=1) @ self.W)\n",
    "        for i in range(len(y)):\n",
    "            if y[i] >= 0.5:\n",
    "                y[i] = 1\n",
    "            else:\n",
    "                y[i] = 0\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_my_model(df, scaler, state):\n",
    "    print(\"Creating model...\")\n",
    "    # Create the logistic regression model\n",
    "    model = MyLogisticRegression(lr=0.01, epochs_no=1000)\n",
    "    # Create an instance of LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Convert categorical variables to numerical labels\n",
    "    for column in df_copy.columns:\n",
    "        df_copy[column] = label_encoder.fit_transform(df_copy[column])\n",
    "\n",
    "    # Split the dataset into features (X) and target variable (y)\n",
    "    X = df_copy.drop(TARGET, axis=1)\n",
    "    y = df_copy[TARGET]\n",
    "\n",
    "    # # Apply the scaler if provided\n",
    "    if scaler is not None:\n",
    "        scaler = scaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=state\n",
    "    )\n",
    "\n",
    "    # Fit the model to the data\n",
    "    model.train(X_train, y_train)\n",
    "\n",
    "    return model, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from my_logistic.pkl\n"
     ]
    }
   ],
   "source": [
    "average_accuracy, average_precision, average_recall, average_f1 = run_logistic(\n",
    "    RANDOM_STATES, SCALERS, create_my_model, \"my_logistic.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler: None\n",
      "Variance of accuracy: 0.006343966508999275\n",
      "Variance of precision: 0.038790129625198115\n",
      "Variance of recall: 0.13611836836165264\n",
      "Variance of F1 score: 0.07257256014119179\n",
      "\n",
      "Average accuracy: 0.8302919708029197\n",
      "Average precision: 0.6453768587044486\n",
      "Average recall: 0.4748927568689555\n",
      "Average F1 score: 0.38064429543706707\n",
      "\n",
      "Scaler: MinMaxScaler\n",
      "Variance of accuracy: 0.00026777145661120987\n",
      "Variance of precision: 0.01846004706894375\n",
      "Variance of recall: 0.010870871790115366\n",
      "Variance of F1 score: 0.014734140804535778\n",
      "\n",
      "Average accuracy: 0.8393349553933496\n",
      "Average precision: 0.444199342523863\n",
      "Average recall: 0.17569543811027605\n",
      "Average F1 score: 0.24192508808478247\n",
      "\n",
      "Scaler: StandardScaler\n",
      "Variance of accuracy: 0.0005511797427989018\n",
      "Variance of precision: 0.0029041635466063895\n",
      "Variance of recall: 0.0049871481737227925\n",
      "Variance of F1 score: 0.002231048857600137\n",
      "\n",
      "Average accuracy: 0.8356447688564476\n",
      "Average precision: 0.484015719119987\n",
      "Average recall: 0.5989587112832753\n",
      "Average F1 score: 0.5322357724744308\n",
      "\n",
      "Scaler: RobustScaler\n",
      "Variance of accuracy: 0.0009443089438915888\n",
      "Variance of precision: 0.032889410977153345\n",
      "Variance of recall: 0.09993290048435524\n",
      "Variance of F1 score: 0.05646958680854919\n",
      "\n",
      "Average accuracy: 0.8325628548256285\n",
      "Average precision: 0.4075246755810563\n",
      "Average recall: 0.6432284577000448\n",
      "Average F1 score: 0.4921691560189584\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.8302919708029197,\n",
       "  0.6453768587044486,\n",
       "  0.4748927568689555,\n",
       "  0.38064429543706707,\n",
       "  0.006343966508999275,\n",
       "  0.038790129625198115,\n",
       "  0.13611836836165264,\n",
       "  0.07257256014119179),\n",
       " (0.8393349553933496,\n",
       "  0.444199342523863,\n",
       "  0.17569543811027605,\n",
       "  0.24192508808478247,\n",
       "  0.00026777145661120987,\n",
       "  0.01846004706894375,\n",
       "  0.010870871790115366,\n",
       "  0.014734140804535778),\n",
       " (0.8356447688564476,\n",
       "  0.484015719119987,\n",
       "  0.5989587112832753,\n",
       "  0.5322357724744308,\n",
       "  0.0005511797427989018,\n",
       "  0.0029041635466063895,\n",
       "  0.0049871481737227925,\n",
       "  0.002231048857600137),\n",
       " (0.8325628548256285,\n",
       "  0.4075246755810563,\n",
       "  0.6432284577000448,\n",
       "  0.4921691560189584,\n",
       "  0.0009443089438915888,\n",
       "  0.032889410977153345,\n",
       "  0.09993290048435524,\n",
       "  0.05646958680854919)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_average_variance(\n",
    "    average_accuracy, average_precision, average_recall, average_f1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
